{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89d64ecb",
   "metadata": {},
   "source": [
    "# Applicazione degli algoritmi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50c200f",
   "metadata": {},
   "source": [
    "### Importazione dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9625776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.exceptions.ConvergenceWarning('ignore')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_validate\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import auc, accuracy_score, roc_curve, recall_score, matthews_corrcoef, f1_score, confusion_matrix\n",
    "from statistics import mean\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ConvergenceWarning(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48618016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importa_dati(path, sep=','):\n",
    "    \"\"\"Funzione per l'importazione di un dataset con un formato csv in un DataFrame di Pandas.\n",
    "       - path: percorso in cui è salvato il file.csv (stringa);\n",
    "       - sep: separatore utilizzato nel file (stringa)\"\"\"\n",
    "    data = pd.read_csv(path, sep=sep)\n",
    "    data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3ab8c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# versione multiclasse\n",
    "df_ohe_multi = importa_dati('/Users/eliaceccolini/Documents/Uni/Tesi/Dataset_finale/Datasets/Dataset_preprocessato_OHE_MULTI.csv')\n",
    "df_le_multi = importa_dati('/Users/eliaceccolini/Documents/Uni/Tesi/Dataset_finale/Datasets/Dataset_preprocessato_LE_MULTI.csv')\n",
    "\n",
    "# version binaria\n",
    "df_ohe_bin = importa_dati('/Users/eliaceccolini/Documents/Uni/Tesi/Dataset_finale/Datasets/Dataset_preprocessato_OHE_BIN.csv')\n",
    "df_le_bin = importa_dati('/Users/eliaceccolini/Documents/Uni/Tesi/Dataset_finale/Datasets/Dataset_preprocessato_LE_BIN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eeb660",
   "metadata": {},
   "source": [
    "***\n",
    "### Divisione della variabile risposta dalle feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1e65d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estrapola_variabile_risposta(data, var):\n",
    "    \"\"\"Funzione per dividere il dataset in X e y, quindi per separare la variabile risposta dalle feature.\n",
    "       - data: Dataset (DataFrame)\n",
    "       - var: nome della variabile risposta (String)\"\"\"\n",
    "    y = data[var]\n",
    "    X = data.drop(var, axis=1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a833fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# versione multi-classe\n",
    "X_le_multi, y_le_multi = estrapola_variabile_risposta(df_le_multi, 'best_response')\n",
    "X_ohe_multi, y_ohe_multi = estrapola_variabile_risposta(df_ohe_multi, 'best_response')\n",
    "\n",
    "# versione binaria\n",
    "X_le_bin, y_le_bin = estrapola_variabile_risposta(df_le_bin, 'best_response')\n",
    "X_ohe_bin, y_ohe_bin = estrapola_variabile_risposta(df_ohe_bin, 'best_response')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bbfbe4",
   "metadata": {},
   "source": [
    "***\n",
    "### Funzione per eseguire cross validation e salvare i relativi grafici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6725be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificazione_crossvalidate(X, y, exp_name, num_trials, p_grid, model=None, model_name=None):\n",
    "    \"\"\"Funzione per evidenziare la t-distributed stochastic neighbor embedding del dataset in due dimensioni\n",
    "       e per applicare il modello model_name al dataset per predire y a partire dalle feature X.\n",
    "       - X: feature usate per la predizione di y (DataFrame)\n",
    "       - y: variabile risposta (Series)\n",
    "       - exp_name: nome dell'esperimento (String)\n",
    "       - num_trials: numero di iterazioni da effettuare per la predizione (int)\n",
    "       - p_grid: parametri della griglia (Dictionary)\n",
    "       - model: modello ML da utilizzare\n",
    "       - model_name: nome del modello (String)\"\"\"\n",
    "    \n",
    "    # visualizzazione del dataset in uno spazio bidimensionale (tsne)\n",
    "    np.random.seed(1)\n",
    "    tsne = TSNE(n_components=2, verbose=0, random_state=123)\n",
    "    z = tsne.fit_transform(X)\n",
    "    df = pd.DataFrame()\n",
    "    df[\"y\"] = y\n",
    "    df[\"comp-1\"] = z[:,0]\n",
    "    df[\"comp-2\"] = z[:,1]\n",
    "    plt.figure()\n",
    "    sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df.y.tolist(),data=df)\n",
    "    plt.title(\"TSNE_\"+exp_name)\n",
    "    plt.savefig(\"immagini/tsne/TSNE_\"+ exp_name +\".png\", dpi=600)\n",
    "    plt.close()\n",
    "    \n",
    "    # divisione del datset in train e test\n",
    "    X, X_test_final, y, y_test_final = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "    \n",
    "    # score che verranno considerati\n",
    "    myscoring = ['balanced_accuracy', 'roc_auc', 'average_precision', 'recall']\n",
    "    \n",
    "    # inizializzazione dei vettori per i punteggi nel train set\n",
    "    nested_scores = np.zeros(num_trials)\n",
    "    bal_acc_train_scores = np.zeros((num_trials,1))\n",
    "    roc_auc_train_scores = np.zeros((num_trials,1))\n",
    "    ave_pre_train_scores = np.zeros((num_trials,1))\n",
    "    recall_train_scores = np.zeros((num_trials,1))\n",
    "    # inizializzazione dei vettori per i punteggi nel test set\n",
    "    bal_acc_test_scores = np.zeros((num_trials,1))\n",
    "    roc_auc_test_scores = np.zeros((num_trials,1))\n",
    "    ave_pre_test_scores = np.zeros((num_trials,1))\n",
    "    recall_test_scores = np.zeros((num_trials,1))\n",
    "    \n",
    "    # inizio iterazioni\n",
    "    for i in range(num_trials):\n",
    "        print('Iterazione numero '+str(i))\n",
    "        np.random.seed(i)\n",
    "        cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "        cv_outer = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "        # definizione griglia\n",
    "        clf = GridSearchCV(model, p_grid, scoring='recall', n_jobs=1, cv=cv_inner, refit=True, return_train_score=True)\n",
    "        # esecuzione della cross validation innestata\n",
    "        scores = cross_validate(clf, X=X, y=y, cv=cv_outer, return_train_score=True, return_estimator=True, scoring=myscoring)\n",
    "        \n",
    "        # salvataggio e stampa dei risultati all'i-esima iterazione\n",
    "        bal_acc_train_scores[i] = np.mean(scores['train_balanced_accuracy'])\n",
    "        roc_auc_train_scores[i] = np.mean(scores['train_roc_auc'])\n",
    "        ave_pre_train_scores[i] = np.mean(scores['train_average_precision'])\n",
    "        recall_train_scores[i] = np.mean(scores['train_recall'])\n",
    "        print('Train: balanced_accuracy ' + str( bal_acc_train_scores[i]))\n",
    "        print('Train: roc_auc ' + str(roc_auc_train_scores[i]))\n",
    "        print('Train: average_precision ' + str(ave_pre_train_scores[i]))\n",
    "        print('Train: recall ' + str(recall_train_scores[i]))\n",
    "        bal_acc_test_scores[i] = np.mean(scores['test_balanced_accuracy'])\n",
    "        roc_auc_test_scores[i] = np.mean(scores['test_roc_auc'])\n",
    "        ave_pre_test_scores[i] = np.mean(scores['test_average_precision'])\n",
    "        recall_test_scores[i] = np.mean(scores['test_recall'])\n",
    "        print('Test: balanced_accuracy ' + str( bal_acc_test_scores[i]))\n",
    "        print('Test: roc_auc ' + str(roc_auc_test_scores[i]))\n",
    "        print('Test: average_precision ' + str(ave_pre_test_scores[i]))\n",
    "        print('Test: recall ' + str(recall_test_scores[i]))\n",
    "        \n",
    "        # fpr: tasso falsi positivi, tpr: tasso veri positivi\n",
    "        mean_fpr = np.linspace(0, 1, 1000)\n",
    "        tprs = []\n",
    "        # divisione train e test set\n",
    "        for j, (train_ix, test_ix) in enumerate(cv_inner.split(X, y)):\n",
    "            X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "            y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "            classifier_fold = scores['estimator'][j].best_estimator_\n",
    "            classifier_fold.fit(X_train, y_train)\n",
    "            y_pred_labels = classifier_fold.predict(X_test)\n",
    "            # rapporto falsi positivi e veri positivi e soglia utilizzata per il loro calcolo\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, y_pred_labels)\n",
    "            # calcolo area sotto la curva\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "        \n",
    "        # plot ROC AUC medie\n",
    "        plt.figure()\n",
    "        plt.plot([0, 1], [0, 1], '--', color='r', label='Random classifier', lw=2, alpha=0.8)\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        plt.title('Mean AUC=%0.3f' % mean_auc)\n",
    "        plt.plot(mean_fpr, mean_tpr, color='b', label='Mean ROC', lw=2, alpha=0.8)\n",
    "\n",
    "        ## calcolo deviazione standard\n",
    "        std_tpr = np.std(tprs, axis=0)\n",
    "        tprs_upper_std = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower_std = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        plt.fill_between(mean_fpr, tprs_lower_std, tprs_upper_std, color='green', alpha=.2,label=r'$\\pm$ 1 SD')\n",
    "\n",
    "        ## calcolo 99.9% CI\n",
    "        z = 3.291\n",
    "        SE = std_tpr / np.sqrt(num_trials * 5)\n",
    "        tprs_upper_95CI = mean_tpr + (z * SE)\n",
    "        tprs_lower_95CI = mean_tpr - (z * SE)\n",
    "        plt.fill_between(mean_fpr, tprs_lower_95CI, tprs_upper_95CI, color='grey', alpha=.5,label=r'$\\pm$ 99.9% CI')\n",
    "        \n",
    "        # salvataggio curva ROC\n",
    "        plt.xlim([-0.05, 1.05])\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "        plt.xlabel('Tasso di Falsi Positivi')\n",
    "        plt.ylabel('Tasso di Veri Positivi')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(\"immagini/ROCcurves/ROCcurve_\" + exp_name + \"_\" + model_name + \".png\", dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "    mean_results_matrix = np.zeros((3,2))\n",
    "\n",
    "    train_accuracy_global_mean = np.mean(bal_acc_train_scores)\n",
    "    train_accuracy_global_std = np.std(bal_acc_train_scores)\n",
    "\n",
    "    test_accuracy_global_mean = np.mean(bal_acc_test_scores)\n",
    "    test_accuracy_global_std = np.std(bal_acc_test_scores)\n",
    "    mean_results_matrix[0,0] = test_accuracy_global_mean\n",
    "    mean_results_matrix[0,1] = test_accuracy_global_std\n",
    "\n",
    "    roc_auc_global_test_mean = np.mean(roc_auc_test_scores)\n",
    "    roc_auc_global_test_std = np.std(roc_auc_test_scores)\n",
    "    mean_results_matrix[1,0] = roc_auc_global_test_mean\n",
    "    mean_results_matrix[1,1] = roc_auc_global_test_std\n",
    "\n",
    "    test_recall_global_mean = np.mean(recall_test_scores)\n",
    "    test_recall_global_std = np.std(recall_test_scores)\n",
    "    mean_results_matrix[2,0] = test_recall_global_mean\n",
    "    mean_results_matrix[2,1] = test_recall_global_std\n",
    "\n",
    "    mean_results_df = pd.DataFrame(data=mean_results_matrix, columns=[\"mean\",\"std\"], index=[\"Test accuracy\",\"Test ROC AUC\",\"Test recall\"])\n",
    "    os.makedirs(\"risultati\", exist_ok=True)\n",
    "    mean_results_df.to_html(\"risultati/Mean_Results_\"+ exp_name + \"_\" + model_name +\".html\")\n",
    "\n",
    "\n",
    "    print(\"Train accuracy mean: \" + str(train_accuracy_global_mean) + \" std: \" + str(train_accuracy_global_std))\n",
    "    print(\"Test ROC AUC mean: \" + str(roc_auc_global_test_mean) + \" std: \" + str(roc_auc_global_test_std))\n",
    "    print(\"Test accuracy mean: \" + str(test_accuracy_global_mean) + \" std: \" + str(test_accuracy_global_std))\n",
    "    print(\"Test recall mean: \" + str(test_recall_global_mean) + \" std: \" + str(test_recall_global_std))\n",
    "\n",
    "\n",
    "    # modello finale\n",
    "    print(\"Training final classifier...\")\n",
    "    clf_final = GridSearchCV(estimator=model, param_grid=p_grid, scoring='recall', \n",
    "                             n_jobs=-1, refit=True, cv=cv_inner, verbose=0, return_train_score=True)\n",
    "    clf_final.fit(X,y)\n",
    "    best_model = clf_final.best_estimator_\n",
    "    print(\"Best final estimator:\")\n",
    "    print(best_model)\n",
    "    \n",
    "    # se il modello è un albero o un random forest vengono stampate e salvate le var più significative\n",
    "    if 'Tree' in model_name or 'Forest' in model_name or 'XGBoost' in model_name:\n",
    "        feature_names = X.columns\n",
    "        feature_importances = best_model.feature_importances_\n",
    "        # Ordinare le feature per importanza in modo decrescente e selezionare solo le prime 10\n",
    "        top_10_indices = feature_importances.argsort()[::-1][:10]\n",
    "        top_10_importances = feature_importances[top_10_indices]\n",
    "        top_10_feature_names = feature_names[top_10_indices]\n",
    "        plt.figure()\n",
    "        plt.barh(range(len(top_10_importances)), top_10_importances, align='center')\n",
    "        plt.yticks(range(len(top_10_importances)), top_10_feature_names)\n",
    "        plt.xlabel('Importanza delle variabili')\n",
    "        plt.ylabel('Variabili')\n",
    "        plt.title('Importanza_variabili_'+exp_name)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('immagini/importanza_variabili/Importanza_variabili_'+exp_name+'.png', dpi=600)\n",
    "        \n",
    "    # se il modello è un SVM vengono stampati e salvati i pesi relativi alle var più significative\n",
    "    if 'SVM' in model_name:\n",
    "        coefficients = abs(best_model.coef_[0])\n",
    "        # associazione dei coefficienti alle variabili\n",
    "        variable_coefficients = list(zip(X_train.columns, coefficients))\n",
    "        # ordinamento in ordine decrescente delle variabili in base al valore assoluto del peso assegnotogli\n",
    "        variable_coefficients.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_10_variables = variable_coefficients[:10]\n",
    "        # Estrazione delle variabili e coefficienti per il grafico\n",
    "        variables, coefficients = zip(*top_10_variables)\n",
    "        plt.figure()\n",
    "        plt.barh(range(len(variables)), coefficients, align='center')\n",
    "        plt.yticks(range(len(variables)), variables)\n",
    "        plt.xlabel('Peso')\n",
    "        plt.ylabel('Variabile')\n",
    "        plt.title('Le prime 10 variabili più importanti')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('immagini/importanza_variabili/Importanza_variabili_'+exp_name+'.png', dpi=600)\n",
    "    \n",
    "        \n",
    "    # se il modello è un albero viene stampata e salvata la struttura dell'albero decisionale\n",
    "    if 'Tree' in model_name:\n",
    "        plt.figure()\n",
    "        plot_tree(decision_tree=best_model, feature_names=list(X.columns))\n",
    "        plt.title('albero_decisionale_'+exp_name)\n",
    "        plt.savefig('immagini/alberi_decisionali/Albero_decisionale_'+exp_name+'.png', dpi=600)\n",
    "    \n",
    "    # salvataggio del modello allenato\n",
    "    os.makedirs(\"modelli\", exist_ok=True)\n",
    "    pickle.dump(best_model, open(\"modelli/Modello_\"+ exp_name + \"_\" + model_name +\".pkl\",'wb'))\n",
    "    \n",
    "    # predizione del test set\n",
    "    y_final_pred_labels = best_model.predict(X_test_final)\n",
    "    final_model_accuracy = accuracy_score(y_test_final, y_final_pred_labels)\n",
    "    # stampa dei punteggi finali\n",
    "    print(\"Final estimator accuracy: \" + str(final_model_accuracy))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_final, y_final_pred_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(\"roc_auc final model: \" + str(np.round(roc_auc,3)))\n",
    "    final_model_recall = recall_score(y_test_final, y_final_pred_labels)\n",
    "    print(\"Final estimator recall: \" + str(final_model_recall))\n",
    "    final_model_matt_corrcoef = matthews_corrcoef(y_test_final, y_final_pred_labels)\n",
    "    print(\"Final estimator Matthews Correlation Coefficient: \" + str(final_model_matt_corrcoef))\n",
    "    final_model_f1score = f1_score(y_test_final, y_final_pred_labels)\n",
    "    print(\"Final estimator F1 score: \" + str(final_model_f1score))\n",
    "    \n",
    "    # stampa e salvataggio della matrice di confusione\n",
    "    conf_matrix = confusion_matrix(y_test_final, y_final_pred_labels)\n",
    "    plt.figure()\n",
    "    plt.title('Matrice_Confusione_' + exp_name)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.savefig('immagini/matrici_confusione/Matrice_confusione_'+exp_name+'.png', dpi=600)\n",
    "    \n",
    "    return final_model_accuracy, roc_auc, final_model_recall, final_model_f1score, final_model_matt_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6af478",
   "metadata": {},
   "source": [
    "***\n",
    "### Applicazione modelli (versione binaria)\n",
    "I modelli che saranno applicati sono:\n",
    "- Naive Bayes\n",
    "- Decision Tree Classifier\n",
    "- Random Forest Classifier\n",
    "- SVM\n",
    "- XGBoost\n",
    "- MLP Classifier - Multi-Layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67cf3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applica_modelli(X, y, exp_name, num_trials):\n",
    "    \"\"\"Funzione per applicare i modelli Naive Bayes, Decision Tree Classifier, Random Forest, SVM, XGBoost e MLP\n",
    "       al dataset data.\n",
    "       - X: feature del dataset (DataFrame)\n",
    "       - y: variabile risposta (Series)\n",
    "       - exp_name: nome esperimento (String)\n",
    "       - num_trials: numero di iterazioni (Int)\"\"\"\n",
    "    \n",
    "    res = np.zeros((6, 5))\n",
    "    \n",
    "    # Naive Bayes\n",
    "    p_grid = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "    model = GaussianNB()\n",
    "    acc, roc_auc, recall, f1score, marr_corrcoef = classificazione_crossvalidate(X, y, 'NB_'+exp_name, num_trials, p_grid, model, 'NaiveBayes')\n",
    "    res[0] = [acc, roc_auc, recall, f1score, marr_corrcoef]\n",
    "    \n",
    "    # Decision Tree Classifier\n",
    "    p_grid = {\"criterion\":['gini','entropy'], \"max_depth\":[2,4,6,8,10,12]}\n",
    "    model = DecisionTreeClassifier()\n",
    "    acc, roc_auc, recall, f1score, marr_corrcoef = classificazione_crossvalidate(X, y, 'DT_'+exp_name, num_trials, p_grid, model, 'DecisionTree')\n",
    "    res[1] = [acc, roc_auc, recall, f1score, marr_corrcoef]\n",
    "    \n",
    "    # Random Forest Classifier\n",
    "    p_grid = {'n_estimators': [5, 10, 15, 20], 'max_depth': [2, 5, 7, 9]}\n",
    "    model = RandomForestClassifier()\n",
    "    acc, roc_auc, recall, f1score, marr_corrcoef = classificazione_crossvalidate(X, y, 'RF_'+exp_name, num_trials, p_grid, model, 'RandomForest')\n",
    "    res[2] = [acc, roc_auc, recall, f1score, marr_corrcoef]\n",
    "    \n",
    "    # SVM\n",
    "    p_grid = {\"C\": [1, 10, 100], \"gamma\": [0.01, 0.1]}\n",
    "    model = SVC(kernel=\"linear\", max_iter=100)\n",
    "    acc, roc_auc, recall, f1score, marr_corrcoef = classificazione_crossvalidate(X, y, 'SVM_'+exp_name, num_trials, p_grid, model, 'SVM')\n",
    "    res[3] = [acc, roc_auc, recall, f1score, marr_corrcoef]\n",
    "    \n",
    "    # XGBoost - le iterazioni sono due perché impiega più di 3 ore con cinquanta\n",
    "    p_grid = {\"gamma\":[0, 0.1, 0.2,0.3,0.4,0.5],\n",
    "              \"max_depth\": [3,5,10],\n",
    "              \"n_estimators\":[5,10, 20, 100],\n",
    "              \"ubsample\": [0.25, 0.5, 1],\n",
    "              \"verbosity\": [0]}\n",
    "    model = XGBClassifier(silent=True)\n",
    "    acc, roc_auc, recall, f1score, marr_corrcoef = classificazione_crossvalidate(X, y, 'XGBoost_'+exp_name, 2, p_grid, model, 'XGBoost')\n",
    "    res[4] = [acc, roc_auc, recall, f1score, marr_corrcoef]\n",
    "    \n",
    "    # MLP\n",
    "    p_grid = {\"hidden_layer_sizes\": [(10,30,10),(20,)],\n",
    "              \"activation\": [\"tanh\", \"relu\"],\n",
    "              \"solver\": [\"sgd\", \"adam\"],\n",
    "              \"alpha\": [0.0001, 0.05],\n",
    "              \"learning_rate\": [\"constant\",\"adaptive\"]}\n",
    "    model = MLPClassifier(max_iter=100)\n",
    "    acc, roc_auc, recall, f1score, marr_corrcoef = classificazione_crossvalidate(X, y, 'MLP_'+exp_name, num_trials, p_grid, model, 'MLP')\n",
    "    res[5] = [acc, roc_auc, recall, f1score, marr_corrcoef]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ded3954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# esperimento: dataset pre-processato con LE nella versione binaria\n",
    "scores_le_bin = applica_modelli(X_le_bin, y_le_bin, 'LE_BIN', 50)\n",
    "\n",
    "# esperimento: dataset pre-processato con OHE nella versione binaria\n",
    "scores_ohe_bin = applica_modelli(X_ohe_bin, y_ohe_bin, 'OHE_BIN', 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
