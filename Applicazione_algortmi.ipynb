{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89d64ecb",
   "metadata": {},
   "source": [
    "# Applicazione degli algoritmi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50c200f",
   "metadata": {},
   "source": [
    "### Importazione dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9625776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.exceptions.ConvergenceWarning('ignore')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_validate\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import auc, accuracy_score, roc_curve, recall_score, matthews_corrcoef, f1_score, confusion_matrix\n",
    "from statistics import mean\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ConvergenceWarning(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48618016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importa_dati(path, sep=','):\n",
    "    \"\"\"Funzione per l'importazione di un dataset con un formato csv in un DataFrame di Pandas.\n",
    "       - path: percorso in cui è salvato il file.csv (stringa);\n",
    "       - sep: separatore utilizzato nel file (stringa)\"\"\"\n",
    "    data = pd.read_csv(path, sep=sep)\n",
    "    data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3ab8c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe = importa_dati('/Users/eliaceccolini/Documents/Uni/Tesi/Dataset_finale/Datasets/Dataset_preprocessato_OHE.csv')\n",
    "df_le = importa_dati('/Users/eliaceccolini/Documents/Uni/Tesi/Dataset_finale/Datasets/Dataset_preprocessato_LE.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba962bb",
   "metadata": {},
   "source": [
    "***\n",
    "### Dati nulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1731912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sostituisci_nulli(data, method):\n",
    "    \"\"\"Funzione per sostiuire i dati nulli utilizzando il metodo method.\n",
    "       - data: Dataset (DataFrame)\n",
    "       - method: metodo con cui sostiuire i nulli (String)\"\"\"\n",
    "    null_cols = [c for c in data.columns if data[c].isnull().sum() > 0]\n",
    "    data.fillna(method=method, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd1f7135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset preprocessato con LE\n",
    "sostituisci_nulli(df_le, 'ffill')\n",
    "\n",
    "# dataset preprocessato con OHE\n",
    "sostituisci_nulli(df_ohe, 'ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eeb660",
   "metadata": {},
   "source": [
    "***\n",
    "### Divisione della variabile risposta dalle feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1e65d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estrapola_variabile_risposta(data, var):\n",
    "    \"\"\"Funzione per dividere il dataset in X e y, quindi per separare la variabile risposta dalle feature.\n",
    "       - data: Dataset (DataFrame)\n",
    "       - var: nome della variabile risposta (String)\"\"\"\n",
    "    y = data[var]\n",
    "    X = data.drop(var, axis=1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a833fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset preprocessato con LE\n",
    "X_le, y_le = estrapola_variabile_risposta(df_le, 'best_response')\n",
    "\n",
    "# dataset preprocessato con OHE\n",
    "X_ohe, y_ohe = estrapola_variabile_risposta(df_ohe, 'best_response')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bbfbe4",
   "metadata": {},
   "source": [
    "***\n",
    "### Funzione per eseguire cross validation e salvare i relativi grafici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6725be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificazione_crossvalidate(X, y, exp_name, num_trials, p_grid, model=None, model_name=None):\n",
    "    \"\"\"Funzione per evidenziare la t-distributed stochastic neighbor embedding del dataset in due dimensioni\n",
    "       e per applicare il modello model_name al dataset per predire y a partire dalle feature X.\n",
    "       - X: feature usate per la predizione di y (DataFrame)\n",
    "       - y: variabile risposta (Series)\n",
    "       - exp_name: nome dell'esperimento (String)\n",
    "       - num_trials: numero di iterazioni da effettuare per la predizione (int)\n",
    "       - p_grid: parametri della griglia (Dictionary)\n",
    "       - model: modello ML da utilizzare\n",
    "       - model_name: nome del modello (String)\"\"\"\n",
    "    \n",
    "    # visualizzazione del dataset in uno spazio bidimensionale (tsne)\n",
    "    np.random.seed(1)\n",
    "    tsne = TSNE(n_components=2, verbose=0, random_state=123)\n",
    "    z = tsne.fit_transform(X)\n",
    "    df = pd.DataFrame()\n",
    "    df[\"y\"] = y\n",
    "    df[\"comp-1\"] = z[:,0]\n",
    "    df[\"comp-2\"] = z[:,1]\n",
    "    plt.figure()\n",
    "    sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df.y.tolist(),data=df)\n",
    "    plt.title(\"TSNE_\"+exp_name)\n",
    "    plt.savefig(\"immagini/tsne/TSNE_\"+ exp_name +\".png\", dpi=600)\n",
    "    plt.close()\n",
    "    \n",
    "    # divisione del datset in train e test\n",
    "    X, X_test_final, y, y_test_final = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "    \n",
    "    # score che verranno considerati\n",
    "    myscoring = ['balanced_accuracy', 'roc_auc', 'average_precision', 'recall']\n",
    "    \n",
    "    # inizializzazione dei vettori per i punteggi nel train set\n",
    "    nested_scores = np.zeros(num_trials)\n",
    "    bal_acc_train_scores = np.zeros((num_trials,1))\n",
    "    roc_auc_train_scores = np.zeros((num_trials,1))\n",
    "    ave_pre_train_scores = np.zeros((num_trials,1))\n",
    "    recall_train_scores = np.zeros((num_trials,1))\n",
    "    # inizializzazione dei vettori per i punteggi nel test set\n",
    "    bal_acc_test_scores = np.zeros((num_trials,1))\n",
    "    roc_auc_test_scores = np.zeros((num_trials,1))\n",
    "    ave_pre_test_scores = np.zeros((num_trials,1))\n",
    "    recall_test_scores = np.zeros((num_trials,1))\n",
    "    \n",
    "    # inizio iterazioni\n",
    "    for i in range(num_trials):\n",
    "        print('Iterazione numero '+str(i))\n",
    "        np.random.seed(i)\n",
    "        cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "        cv_outer = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "        # definizione griglia\n",
    "        clf = GridSearchCV(model, p_grid, scoring='recall', n_jobs=1, cv=cv_inner, refit=True, return_train_score=True)\n",
    "        # esecuzione della cross validation innestata\n",
    "        scores = cross_validate(clf, X=X, y=y, cv=cv_outer, return_train_score=True, return_estimator=True, scoring=myscoring)\n",
    "        \n",
    "        # salvataggio e stampa dei risultati all'i-esima iterazione\n",
    "        bal_acc_train_scores[i] = np.mean(scores['train_balanced_accuracy'])\n",
    "        roc_auc_train_scores[i] = np.mean(scores['train_roc_auc'])\n",
    "        ave_pre_train_scores[i] = np.mean(scores['train_average_precision'])\n",
    "        recall_train_scores[i] = np.mean(scores['train_recall'])\n",
    "        print('Train: balanced_accuracy ' + str( bal_acc_train_scores[i]))\n",
    "        print('Train: roc_auc ' + str(roc_auc_train_scores[i]))\n",
    "        print('Train: average_precision ' + str(ave_pre_train_scores[i]))\n",
    "        print('Train: recall ' + str(recall_train_scores[i]))\n",
    "        bal_acc_test_scores[i] = np.mean(scores['test_balanced_accuracy'])\n",
    "        roc_auc_test_scores[i] = np.mean(scores['test_roc_auc'])\n",
    "        ave_pre_test_scores[i] = np.mean(scores['test_average_precision'])\n",
    "        recall_test_scores[i] = np.mean(scores['test_recall'])\n",
    "        print('Test: balanced_accuracy ' + str( bal_acc_test_scores[i]))\n",
    "        print('Test: roc_auc ' + str(roc_auc_test_scores[i]))\n",
    "        print('Test: average_precision ' + str(ave_pre_test_scores[i]))\n",
    "        print('Test: recall ' + str(recall_test_scores[i]))\n",
    "        \n",
    "        # fpr: tasso falsi positivi, tpr: tasso veri positivi\n",
    "        mean_fpr = np.linspace(0, 1, 1000)\n",
    "        tprs = []\n",
    "        # divisione train e test set\n",
    "        for j, (train_ix, test_ix) in enumerate(cv_inner.split(X, y)):\n",
    "            X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "            y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "            classifier_fold = scores['estimator'][j].best_estimator_\n",
    "            classifier_fold.fit(X_train, y_train)\n",
    "            y_pred_labels = classifier_fold.predict(X_test)\n",
    "            # rapporto falsi positivi e veri positivi e soglia utilizzata per il loro calcolo\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, y_pred_labels)\n",
    "            # calcolo area sotto la curva\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "        \n",
    "        # plot ROC AUC medie\n",
    "        plt.figure()\n",
    "        plt.plot([0, 1], [0, 1], '--', color='r', label='Random classifier', lw=2, alpha=0.8)\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        plt.title('Mean AUC=%0.3f' % mean_auc)\n",
    "        plt.plot(mean_fpr, mean_tpr, color='b', label='Mean ROC', lw=2, alpha=0.8)\n",
    "\n",
    "        ## calcolo deviazione standard\n",
    "        std_tpr = np.std(tprs, axis=0)\n",
    "        tprs_upper_std = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower_std = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        plt.fill_between(mean_fpr, tprs_lower_std, tprs_upper_std, color='green', alpha=.2,label=r'$\\pm$ 1 SD')\n",
    "\n",
    "        ## calcolo 99.9% CI\n",
    "        z = 3.291\n",
    "        SE = std_tpr / np.sqrt(num_trials * 5)\n",
    "        tprs_upper_95CI = mean_tpr + (z * SE)\n",
    "        tprs_lower_95CI = mean_tpr - (z * SE)\n",
    "        plt.fill_between(mean_fpr, tprs_lower_95CI, tprs_upper_95CI, color='grey', alpha=.5,label=r'$\\pm$ 99.9% CI')\n",
    "        \n",
    "        # salvataggio curva ROC\n",
    "        plt.xlim([-0.05, 1.05])\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "        plt.xlabel('Tasso di Falsi Positivi')\n",
    "        plt.ylabel('Tasso di Veri Positivi')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        os.makedirs(\"ROCcurves\", exist_ok=True)\n",
    "        plt.savefig(\"immagini/ROCcurves/ROCcurve_\" + exp_name + \"_\" + model_name + \".png\", dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "    mean_results_matrix = np.zeros((3,2))\n",
    "\n",
    "    train_accuracy_global_mean = np.mean(bal_acc_train_scores)\n",
    "    train_accuracy_global_std = np.std(bal_acc_train_scores)\n",
    "\n",
    "    test_accuracy_global_mean = np.mean(bal_acc_test_scores)\n",
    "    test_accuracy_global_std = np.std(bal_acc_test_scores)\n",
    "    mean_results_matrix[0,0] = test_accuracy_global_mean\n",
    "    mean_results_matrix[0,1] = test_accuracy_global_std\n",
    "\n",
    "    roc_auc_global_test_mean = np.mean(roc_auc_test_scores)\n",
    "    roc_auc_global_test_std = np.std(roc_auc_test_scores)\n",
    "    mean_results_matrix[1,0] = roc_auc_global_test_mean\n",
    "    mean_results_matrix[1,1] = roc_auc_global_test_std\n",
    "\n",
    "    test_recall_global_mean = np.mean(recall_test_scores)\n",
    "    test_recall_global_std = np.std(recall_test_scores)\n",
    "    mean_results_matrix[2,0] = test_recall_global_mean\n",
    "    mean_results_matrix[2,1] = test_recall_global_std\n",
    "\n",
    "    mean_results_df = pd.DataFrame(data=mean_results_matrix, columns=[\"mean\",\"std\"], index=[\"Test accuracy\",\"Test ROC AUC\",\"Test recall\"])\n",
    "    os.makedirs(\"risultati\", exist_ok=True)\n",
    "    mean_results_df.to_html(\"risultati/Mean_Results_\"+ exp_name + \"_\" + model_name +\".html\")\n",
    "\n",
    "\n",
    "    print(\"Train accuracy mean: \" + str(train_accuracy_global_mean) + \" std: \" + str(train_accuracy_global_std))\n",
    "    print(\"Test ROC AUC mean: \" + str(roc_auc_global_test_mean) + \" std: \" + str(roc_auc_global_test_std))\n",
    "    print(\"Test accuracy mean: \" + str(test_accuracy_global_mean) + \" std: \" + str(test_accuracy_global_std))\n",
    "    print(\"Test recall mean: \" + str(test_recall_global_mean) + \" std: \" + str(test_recall_global_std))\n",
    "\n",
    "\n",
    "    # modello finale\n",
    "    print(\"Training final classifier...\")\n",
    "    clf_final = GridSearchCV(estimator=model, param_grid=p_grid, scoring='recall', \n",
    "                             n_jobs=-1, refit=True, cv=cv_inner, verbose=0, return_train_score=True)\n",
    "    clf_final.fit(X,y)\n",
    "    best_model = clf_final.best_estimator_\n",
    "    print(\"Best final estimator:\")\n",
    "    print(best_model)\n",
    "    \n",
    "    # se il modello è un albero o un random forest vengono stampate e salvate le var più significative\n",
    "    if ('Tree' in model_name or 'Forest' in model_name or 'XGBoost' in model_name):\n",
    "        feature_names = X.columns\n",
    "        feature_importances = best_model.feature_importances_\n",
    "        # Ordinare le feature per importanza in modo decrescente e selezionare solo le prime 10\n",
    "        top_10_indices = feature_importances.argsort()[::-1][:10]\n",
    "        top_10_importances = feature_importances[top_10_indices]\n",
    "        top_10_feature_names = feature_names[top_10_indices]\n",
    "        plt.figure()\n",
    "        plt.barh(range(len(top_10_importances)), top_10_importances, align='center')\n",
    "        plt.yticks(range(len(top_10_importances)), top_10_feature_names)\n",
    "        plt.xlabel('Importanza delle variabili')\n",
    "        plt.ylabel('Variabili')\n",
    "        plt.title('Decision Tree Feature Importances')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('immagini/importanza_variabili/Importanza_variabili_'+exp_name+'.png', dpi=600)\n",
    "        \n",
    "    # se il modello è un SVM vengono stampati e salvati i pesi relativi alle var più significative\n",
    "    if 'SVM' in model_name:\n",
    "        coefficients = model.coef_\n",
    "        # associazione dei coefficienti alle variabili\n",
    "        variable_coefficients = list(zip(X_train.columns, coefficients))\n",
    "        # ordinamento in ordine decrescente delle variabili in base al valore assoluto del peso assegnotogli\n",
    "        variable_coefficients.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        top_10_variables = variable_coefficients[:10]\n",
    "        # Estrazione delle variabili e coefficienti per il grafico\n",
    "        variables, coefficients = zip(*top_10_variables)\n",
    "        plt.figure()\n",
    "        plt.barh(range(len(variables)), coefficients, align='center')\n",
    "        plt.yticks(range(len(variables)), variables)\n",
    "        plt.xlabel('Peso')\n",
    "        plt.ylabel('Variabile')\n",
    "        plt.title('Le prime 10 variabili più importanti')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('immagini/importanza_variabili/Importanza_variabili_'+exp_name+'.png', dpi=600)\n",
    "        \n",
    "    # se il modello è un albero viene stampata e salvata la struttura dell'albero decisionale\n",
    "    if 'Tree' in model_name:\n",
    "        plt.figure()\n",
    "        plt.title('albero_decisionale'+exp_name)\n",
    "        plot_tree(decision_tree=best_model, feature_names=X.columns)\n",
    "        plt.savefig('immagini/alberi_decisionali/Albero_decisionale_'+exp_name+'.png', dpi=600)\n",
    "    \n",
    "    # salvataggio del modello allenato\n",
    "    os.makedirs(\"modelli\", exist_ok=True)\n",
    "    pickle.dump(best_model, open(\"modelli/Modello_\"+ exp_name + \"_\" + model_name +\".pkl\",'wb'))\n",
    "    \n",
    "    # predizione del test set\n",
    "    y_final_pred_labels = best_model.predict(X_test_final)\n",
    "    final_model_accuracy = accuracy_score(y_test_final, y_final_pred_labels)\n",
    "    # stampa dei punteggi finali\n",
    "    print(\"Final estimator accuracy: \" + str(final_model_accuracy))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_final, y_final_pred_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(\"roc_auc final model: \" + str(np.round(roc_auc,3)))\n",
    "    final_model_recall = recall_score(y_test_final, y_final_pred_labels)\n",
    "    print(\"Final estimator recall: \" + str(final_model_recall))\n",
    "    final_model_matt_corrcoef = matthews_corrcoef(y_test_final, y_final_pred_labels)\n",
    "    print(\"Final estimator Matthews Correlation Coefficient: \" + str(final_model_matt_corrcoef))\n",
    "    final_model_f1score = f1_score(y_test_final, y_final_pred_labels)\n",
    "    print(\"Final estimator F1 score: \" + str(final_model_f1score))\n",
    "    \n",
    "    # stampa e salvataggio della matrice di confusione\n",
    "    conf_matrix = confusion_matrix(y_test_final, y_final_pred_labels)\n",
    "    plt.figure()\n",
    "    plt.title('Matrice_Confusione_' + exp_name)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.savefig('immagini/matrici_confusione/Matrice_confusione_'+exp_name+'.png', dpi=600)\n",
    "    \n",
    "    return final_model_accuracy, roc_auc, final_model_recall, final_model_f1score, final_model_matt_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6af478",
   "metadata": {},
   "source": [
    "***\n",
    "### Applicazione modelli\n",
    "I modelli che saranno applicati sono:\n",
    "- Naive Bayes\n",
    "- Decision Tree Classifier\n",
    "- Random Forest Classifier\n",
    "- SVM\n",
    "- XGBoost\n",
    "- MLP (devo ancora aggiungerlo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67cf3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applica_modelli(X, y, exp_name):\n",
    "    \"\"\"Funzione per applicare i modelli Naive Bayes, Decision Tree Classifier, Random Forest, SVM, XGBoost e MLP\n",
    "       al dataset data.\n",
    "       - X: feature del dataset (DataFrame)\n",
    "       - y: variabile risposta (Series)\n",
    "       - exp_name: nome esperimento (String)\"\"\"\n",
    "    \n",
    "    res = np.zeros((5, 5))\n",
    "    \n",
    "    # Naive Bayes\n",
    "    p_grid = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "    model = GaussianNB()\n",
    "    acc, roc_auc, recall, f1score, marr_corrcoef = classificazione_crossvalidate(X, y, 'NB_'+exp_name, 50, p_grid, model, 'NaiveBayes')\n",
    "    res[0] = [acc, roc_auc, recall, f1score, marr_corrcoef]\n",
    "    \n",
    "    # Decision Tree Classifier\n",
    "    p_grid = {\"criterion\":['gini','entropy'], \"max_depth\":[2,4,6,8,10,12]}\n",
    "    model = DecisionTreeClassifier()\n",
    "    acc, roc_auc, recall, f1score, marr_corrcoef = classificazione_crossvalidate(X, y, 'DT_'+exp_name, 50, p_grid, model, 'DecisionTree')\n",
    "    res[1] = [acc, roc_auc, recall, f1score, marr_corrcoef]\n",
    "    \n",
    "    # Random Forest Classifier\n",
    "    p_grid = {'n_estimators': [5, 10, 15, 20], 'max_depth': [2, 5, 7, 9]}\n",
    "    model = RandomForestClassifier()\n",
    "    acc, roc_auc, recall, f1score, marr_corrcoef = classificazione_crossvalidate(X, y, 'RF_'+exp_name, 50, p_grid, model, 'RandomForest')\n",
    "    res[2] = [acc, roc_auc, recall, f1score, marr_corrcoef]\n",
    "    \n",
    "    # SVM\n",
    "    p_grid = {\"C\": [1, 10, 100], \"gamma\": [0.01, 0.1]}\n",
    "    model = SVC(kernel=\"linear\", max_iter=100)\n",
    "    acc, roc_auc, recall, f1score, marr_corrcoef = classificazione_crossvalidate(X, y, 'SVM_'+exp_name, 50, p_grid, model, 'SVM')\n",
    "    res[3] = [acc, roc_auc, recall, f1score, marr_corrcoef]\n",
    "    \n",
    "    # XGBoost\n",
    "    p_grid = {\"gamma\":[0, 0.1, 0.2,0.3,0.4,0.5],\n",
    "              \"max_depth\": [3,5,10],\n",
    "              \"n_estimators\":[5,10, 20, 100],\n",
    "              \"ubsample\": [0.25, 0.5, 1],\n",
    "              \"verbosity\": [0]}\n",
    "    model = XGBClassifier(silent=True)\n",
    "    acc, roc_auc, recall, f1score, marr_corrcoef = classificazione_crossvalidate(X, y, 'XGBoost_'+exp_name, 50, p_grid, model, 'XGBoost')\n",
    "    res[4] = [acc, roc_auc, recall, f1score, marr_corrcoef]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ded3954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# esperimento: dataset pre-processato con LE nella versione binaria\n",
    "#scores_le = applica_modelli(X_le, y_le, 'LE_BIN')\n",
    "\n",
    "# esperimento: dataset pre-processato con OHE nella versione binaria\n",
    "#scores_ohe = applica_modelli(X_ohe, y_ohe, 'OHE_BIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76519aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterazione numero 0\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 1\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 2\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 3\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 4\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 5\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 6\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 7\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 8\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 9\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 10\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 11\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 12\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 13\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 14\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 15\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 16\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 17\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 18\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 19\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 20\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 21\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 22\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 23\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 24\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 25\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 26\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 27\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 28\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 29\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterazione numero 30\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 31\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 32\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 33\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 34\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 35\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 36\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 37\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 38\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 39\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 40\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 41\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 42\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 43\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 44\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 45\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 46\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 47\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 48\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Iterazione numero 49\n",
      "Train: balanced_accuracy [0.49092145]\n",
      "Train: roc_auc [0.47958208]\n",
      "Train: average_precision [0.55741263]\n",
      "Train: recall [0.60592591]\n",
      "Test: balanced_accuracy [0.5132104]\n",
      "Test: roc_auc [0.48408858]\n",
      "Test: average_precision [0.56984452]\n",
      "Test: recall [0.64441963]\n",
      "Train accuracy mean: 0.49092144727879455 std: 5.551115123125783e-17\n",
      "Test ROC AUC mean: 0.4840885838479823 std: 5.551115123125783e-17\n",
      "Test accuracy mean: 0.5132104024735604 std: 0.0\n",
      "Test recall mean: 0.6444196349459509 std: 1.1102230246251565e-16\n",
      "Training final classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best final estimator:\n",
      "SVC(C=1, gamma=0.01, kernel='linear', max_iter=100)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SVC' object has no attribute 'dual_coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m p_grid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m]}\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m acc, roc_auc, recall, f1score, marr_corrcoef \u001b[38;5;241m=\u001b[39m \u001b[43mclassificazione_crossvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_le\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_le\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSVM_LE_BIN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSVM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mclassificazione_crossvalidate\u001b[0;34m(X, y, exp_name, num_trials, p_grid, model, model_name)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# se il modello è un SVM vengono stampati e salvati i pesi relativi alle var più significative\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_name:\n\u001b[0;32m--> 182\u001b[0m     coefficients \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# associazione dei coefficienti alle variabili\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     variable_coefficients \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mcolumns, coefficients))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:660\u001b[0m, in \u001b[0;36mBaseLibSVM.coef_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoef_ is only available when using a linear kernel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 660\u001b[0m coef \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_coef\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# coef_ being a read-only property, it's better to mark the value as\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;66;03m# immutable to avoid hiding potential bugs for the unsuspecting user.\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(coef):\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;66;03m# sparse matrix do not have global flags\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_base.py:967\u001b[0m, in \u001b[0;36mBaseSVC._get_coef\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_coef\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 967\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdual_coef_\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    968\u001b[0m         \u001b[38;5;66;03m# binary classifier\u001b[39;00m\n\u001b[1;32m    969\u001b[0m         coef \u001b[38;5;241m=\u001b[39m safe_sparse_dot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_)\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    971\u001b[0m         \u001b[38;5;66;03m# 1vs1 classifier\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SVC' object has no attribute 'dual_coef_'"
     ]
    }
   ],
   "source": [
    "p_grid = {\"C\": [1, 10, 100], \"gamma\": [0.01, 0.1]}\n",
    "model = SVC(kernel=\"linear\", max_iter=100)\n",
    "acc, roc_auc, recall, f1score, marr_corrcoef = classificazione_crossvalidate(X_le, y_le, 'SVM_LE_BIN', 50, p_grid, model, 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c607ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
